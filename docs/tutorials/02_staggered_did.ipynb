{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Staggered Difference-in-Differences\n\nThis notebook demonstrates how to handle **staggered treatment adoption** using modern DiD estimators. In staggered DiD settings:\n\n- Different units get treated at different times\n- Traditional TWFE can give biased estimates due to \"forbidden comparisons\"\n- Modern estimators compute group-time specific effects and aggregate them properly\n\nWe'll cover:\n1. Understanding staggered adoption\n2. The problem with TWFE (and Goodman-Bacon decomposition)\n3. The Callaway-Sant'Anna estimator\n4. Group-time effects ATT(g,t)\n5. Aggregating effects (simple, group, event-study)\n6. Bootstrap inference for valid standard errors\n7. Visualization\n8. Pre-treatment effects and parallel trends testing\n9. Different control group options\n10. Handling anticipation effects\n11. Adding covariates\n12. Comparing with MultiPeriodDiD\n13. Sun-Abraham interaction-weighted estimator\n14. Comparing CS and SA as a robustness check"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from diff_diff import CallawaySantAnna, SunAbraham, MultiPeriodDiD\n",
    "from diff_diff.visualization import plot_event_study, plot_group_effects\n",
    "\n",
    "# For nicer plots (optional)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    HAS_MATPLOTLIB = False\n",
    "    print(\"matplotlib not installed - visualization examples will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Staggered Adoption\n",
    "\n",
    "In a staggered adoption design, units adopt treatment at different times. We call the period when a unit first receives treatment its **cohort** or **group**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate staggered adoption data using the library function\n",
    "from diff_diff import generate_staggered_data\n",
    "\n",
    "# Generate data with 100 units, 8 periods, two treatment cohorts (periods 3 and 5),\n",
    "# and 40% never-treated\n",
    "df = generate_staggered_data(\n",
    "    n_units=100,\n",
    "    n_periods=8,\n",
    "    cohort_periods=[3, 5],  # Treatment cohorts at periods 3 and 5\n",
    "    never_treated_frac=0.4,\n",
    "    treatment_effect=2.0,\n",
    "    dynamic_effects=True,\n",
    "    effect_growth=0.5,  # Effect grows 0.5 per period\n",
    "    unit_fe_sd=2.0,\n",
    "    noise_sd=0.5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# The DGP returns 'first_treat' column: 0 = never-treated, >0 = first treatment period\n",
    "\n",
    "print(f\"Dataset: {len(df)} observations, {df['unit'].nunique()} units, {df['period'].nunique()} periods\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine treatment timing\n",
    "cohort_summary = df.groupby('unit').agg({'first_treat': 'first', 'treated': 'sum'}).reset_index()\n",
    "print(\"Treatment cohorts:\")\n",
    "print(cohort_summary.groupby('first_treat').size())\n",
    "\n",
    "print(\"\\nTreatment adoption over time:\")\n",
    "print(df.groupby('period')['treated'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Problem with TWFE in Staggered Settings\n",
    "\n",
    "Traditional Two-Way Fixed Effects (TWFE) can give biased estimates because:\n",
    "- It uses already-treated units as controls for newly-treated units\n",
    "- With heterogeneous treatment effects, this leads to \"negative weighting\"\n",
    "\n",
    "Let's see what TWFE would give us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_diff import TwoWayFixedEffects\n",
    "\n",
    "# TWFE estimation (potentially biased with heterogeneous effects)\n",
    "twfe = TwoWayFixedEffects()\n",
    "results_twfe = twfe.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    treatment=\"treated\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\"\n",
    ")\n",
    "\n",
    "print(\"TWFE Estimate (potentially biased):\")\n",
    "print(f\"ATT: {results_twfe.att:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding *Why* TWFE Fails: Goodman-Bacon Decomposition\n",
    "\n",
    "The Goodman-Bacon (2021) decomposition reveals exactly why TWFE can be biased. It shows that the TWFE estimate is a weighted average of all possible 2x2 DiD comparisons, including problematic \"forbidden comparisons\" where already-treated units are used as controls.\n",
    "\n",
    "There are three types of comparisons:\n",
    "1. **Treated vs Never-treated** (green): Clean comparisons using never-treated units\n",
    "2. **Earlier vs Later treated** (blue): Uses later-treated as controls before they're treated\n",
    "3. **Later vs Earlier treated** (red): Uses already-treated as controls — the \"forbidden comparisons\"\n",
    "\n",
    "When treatment effects are heterogeneous (as in our data where effects grow over time), the forbidden comparisons can bias the TWFE estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_diff import bacon_decompose, plot_bacon\n",
    "\n",
    "# Perform the Goodman-Bacon decomposition\n",
    "bacon_results = bacon_decompose(\n",
    "    df,\n",
    "    outcome='outcome',\n",
    "    unit='unit',\n",
    "    time='period',\n",
    "    first_treat='first_treat'  # 0 means never-treated\n",
    ")\n",
    "\n",
    "# View the decomposition summary\n",
    "bacon_results.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decomposition\n",
    "if HAS_MATPLOTLIB:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Scatter plot: shows each 2x2 comparison\n",
    "    plot_bacon(bacon_results, ax=axes[0], plot_type='scatter', show=False)\n",
    "    \n",
    "    # Bar chart: shows total weight by comparison type\n",
    "    plot_bacon(bacon_results, ax=axes[1], plot_type='bar', show=False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpret the results\n",
    "    forbidden_weight = bacon_results.total_weight_later_vs_earlier\n",
    "    print(f\"\\n⚠️  {forbidden_weight:.1%} of the TWFE weight comes from 'forbidden comparisons'\")\n",
    "    print(\"   where already-treated units are used as controls.\")\n",
    "    print(\"\\n→ This explains why TWFE can be biased. Use Callaway-Sant'Anna instead!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Callaway-Sant'Anna Estimator\n",
    "\n",
    "The CS estimator avoids these problems by:\n",
    "1. Computing separate effects for each (group, time) pair: ATT(g,t)\n",
    "2. Only using not-yet-treated or never-treated units as controls\n",
    "3. Properly aggregating these effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callaway-Sant'Anna estimation\n",
    "cs = CallawaySantAnna(\n",
    "    control_group=\"never_treated\",  # Use never-treated as controls\n",
    "    anticipation=0  # No anticipation effects\n",
    ")\n",
    "\n",
    "results_cs = cs.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\",  # Column with first treatment period (0 = never treated)\n",
    "    aggregate=\"all\"  # Compute all aggregations (simple, event_study, group)\n",
    ")\n",
    "\n",
    "print(results_cs.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Group-Time Effects ATT(g,t)\n",
    "\n",
    "The CS estimator computes separate effects for each combination of:\n",
    "- **g**: Treatment cohort (when the group was first treated)\n",
    "- **t**: Calendar time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all group-time effects\n",
    "print(\"Group-Time Effects ATT(g,t):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for (g, t), data in results_cs.group_time_effects.items():\n",
    "    sig = \"*\" if data['p_value'] < 0.05 else \"\"\n",
    "    print(f\"ATT({g},{t}): {data['effect']:>7.4f} \"\n",
    "          f\"(SE: {data['se']:.4f}, p: {data['p_value']:.3f}) {sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "gt_df = results_cs.to_dataframe()\n",
    "print(\"\\nGroup-time effects as DataFrame:\")\n",
    "gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aggregating Effects\n",
    "\n",
    "We often want to summarize the group-time effects into a single number or event-study style estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple aggregation: weighted average across all (g,t)\n",
    "# This is computed automatically and stored in overall_att/overall_se\n",
    "print(\"Simple Aggregation (Overall ATT):\")\n",
    "print(f\"ATT: {results_cs.overall_att:.4f}\")\n",
    "print(f\"SE: {results_cs.overall_se:.4f}\")\n",
    "print(f\"95% CI: [{results_cs.overall_conf_int[0]:.4f}, {results_cs.overall_conf_int[1]:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group aggregation: average effect by cohort\n",
    "# Requires aggregate=\"group\" or \"all\" in fit()\n",
    "print(\"\\nGroup Aggregation (ATT by cohort):\")\n",
    "for cohort, effects in results_cs.group_effects.items():\n",
    "    print(f\"Cohort {cohort}: ATT = {effects['effect']:.4f} (SE: {effects['se']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event-study aggregation: average effect by time relative to treatment\n",
    "# Requires aggregate=\"event_study\" or \"all\" in fit()\n",
    "print(\"\\nEvent-Study Aggregation (ATT by event time):\")\n",
    "print(f\"{'Event Time':>12} {'ATT':>10} {'SE':>10} {'95% CI':>25}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for event_time in sorted(results_cs.event_study_effects.keys()):\n",
    "    effects = results_cs.event_study_effects[event_time]\n",
    "    ci = effects['conf_int']\n",
    "    print(f\"{event_time:>12} {effects['effect']:>10.4f} {effects['se']:>10.4f} \"\n",
    "          f\"[{ci[0]:>8.4f}, {ci[1]:>8.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bootstrap Inference\n",
    "\n",
    "With few clusters or when analytical standard errors may be unreliable, the **multiplier bootstrap** provides valid inference. This implements the approach from Callaway & Sant'Anna (2021), perturbing unit-level influence functions.\n",
    "\n",
    "**Why use bootstrap?**\n",
    "- Analytical SEs may understate uncertainty with few clusters\n",
    "- Bootstrap provides finite-sample valid confidence intervals\n",
    "- P-values are computed from the bootstrap distribution\n",
    "\n",
    "**Weight types:**\n",
    "- `'rademacher'` - Default, ±1 with p=0.5, good for most cases\n",
    "- `'mammen'` - Two-point distribution, matches first 3 moments\n",
    "- `'webb'` - Six-point distribution, recommended for very few clusters (<10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callaway-Sant'Anna with bootstrap inference\n",
    "cs_boot = CallawaySantAnna(\n",
    "    control_group=\"never_treated\",\n",
    "    n_bootstrap=499,              # Number of bootstrap iterations\n",
    "    bootstrap_weights='rademacher',  # or 'mammen', 'webb'\n",
    "    seed=42                        # For reproducibility\n",
    ")\n",
    "\n",
    "results_boot = cs_boot.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\",    # Column with first treatment period\n",
    "    aggregate=\"event_study\"       # Compute event study aggregation\n",
    ")\n",
    "\n",
    "# Access bootstrap results\n",
    "print(\"Bootstrap Inference Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOverall ATT: {results_boot.overall_att:.4f}\")\n",
    "print(f\"Bootstrap SE: {results_boot.bootstrap_results.overall_att_se:.4f}\")\n",
    "print(f\"Bootstrap 95% CI: [{results_boot.bootstrap_results.overall_att_ci[0]:.4f}, \"\n",
    "      f\"{results_boot.bootstrap_results.overall_att_ci[1]:.4f}]\")\n",
    "print(f\"Bootstrap p-value: {results_boot.bootstrap_results.overall_att_p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event study with bootstrap confidence intervals\n",
    "print(\"\\nEvent Study with Bootstrap Inference:\")\n",
    "print(f\"{'Event Time':>12} {'ATT':>10} {'Boot SE':>10} {'Boot 95% CI':>25} {'p-value':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "event_ses = results_boot.bootstrap_results.event_study_ses\n",
    "event_cis = results_boot.bootstrap_results.event_study_cis\n",
    "event_pvals = results_boot.bootstrap_results.event_study_p_values\n",
    "\n",
    "for event_time in sorted(event_ses.keys()):\n",
    "    att = results_boot.event_study_effects[event_time]['effect']\n",
    "    se = event_ses[event_time]\n",
    "    ci = event_cis[event_time]\n",
    "    pval = event_pvals[event_time]\n",
    "    sig = \"*\" if pval < 0.05 else \"\"\n",
    "    print(f\"{event_time:>12} {att:>10.4f} {se:>10.4f} [{ci[0]:>8.4f}, {ci[1]:>8.4f}] {pval:>10.4f} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization\n",
    "\n",
    "Event-study plots are the standard way to visualize DiD results with multiple periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_MATPLOTLIB:\n",
    "    # Event study plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plot_event_study(\n",
    "        results=results_cs,\n",
    "        ax=ax,\n",
    "        title=\"Event Study: Effect of Treatment Over Time\",\n",
    "        xlabel=\"Periods Since Treatment\",\n",
    "        ylabel=\"ATT\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Install matplotlib to see visualizations: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_MATPLOTLIB:\n",
    "    # Plot effects by cohort\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plot_group_effects(\n",
    "        results=results_cs,\n",
    "        ax=ax,\n",
    "        title=\"Treatment Effects by Cohort\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pre-Treatment Effects and Parallel Trends Testing\n",
    "\n",
    "The Callaway-Sant'Anna estimator can compute **pre-treatment effects** ATT(g,t) for periods before treatment. These should be near zero if parallel trends holds.\n",
    "\n",
    "The `base_period` parameter controls how the reference period is selected:\n",
    "- `\"varying\"` (default): For pre-treatment periods, compares t to t-1 (consecutive comparisons)\n",
    "- `\"universal\"`: Always compares to g-1 (or g-anticipation-1 when anticipation > 0)\n",
    "\n",
    "Both produce identical post-treatment effects; they differ only for pre-treatment diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CallawaySantAnna with explicit base_period for pre-treatment effects\n",
    "cs_pretrends = CallawaySantAnna(\n",
    "    control_group=\"never_treated\",\n",
    "    base_period=\"varying\"  # Default: consecutive comparisons for pre-periods\n",
    ")\n",
    "\n",
    "results_pretrends = cs_pretrends.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\",\n",
    "    aggregate=\"event_study\"\n",
    ")\n",
    "\n",
    "# The base_period is recorded in results\n",
    "print(f\"Base period method: {results_pretrends.base_period}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine pre-treatment effects (event time < 0)\n",
    "print(\"Pre-Treatment Effects (Parallel Trends Diagnostic):\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Event Time':>12} {'ATT':>10} {'SE':>10} {'95% CI':>25} {'Test'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "pre_period_effects = []\n",
    "for event_time in sorted(results_pretrends.event_study_effects.keys()):\n",
    "    if event_time < 0:\n",
    "        effects = results_pretrends.event_study_effects[event_time]\n",
    "        ci = effects['conf_int']\n",
    "        includes_zero = ci[0] <= 0 <= ci[1]\n",
    "        marker = \"Pass\" if includes_zero else \"Fail\"\n",
    "        pre_period_effects.append(effects['effect'])\n",
    "        print(f\"{event_time:>12} {effects['effect']:>10.4f} {effects['se']:>10.4f} \"\n",
    "              f\"[{ci[0]:>8.4f}, {ci[1]:>8.4f}] {marker}\")\n",
    "\n",
    "if pre_period_effects:\n",
    "    print(f\"\\n-> All pre-treatment effects should be close to zero\")\n",
    "    print(f\"   Mean pre-treatment effect: {np.mean(pre_period_effects):.4f}\")\n",
    "else:\n",
    "    print(\"No pre-treatment effects computed (insufficient pre-periods)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Base Period Methods\n",
    "\n",
    "Let's compare the two base period methods to understand their difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare varying vs universal base period\n",
    "cs_universal = CallawaySantAnna(\n",
    "    control_group=\"never_treated\",\n",
    "    base_period=\"universal\"  # Always use g-1 as base (g-anticipation-1 if anticipation > 0)\n",
    ")\n",
    "\n",
    "results_universal = cs_universal.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\",\n",
    "    aggregate=\"event_study\"\n",
    ")\n",
    "\n",
    "print(\"Pre-Treatment Effects: Varying vs Universal Base Period\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Event Time':>12} {'Varying':>12} {'Universal':>12} {'Difference':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for event_time in sorted(results_pretrends.event_study_effects.keys()):\n",
    "    if event_time < 0:\n",
    "        varying_eff = results_pretrends.event_study_effects[event_time]['effect']\n",
    "        universal_eff = results_universal.event_study_effects.get(event_time, {}).get('effect', np.nan)\n",
    "        diff = varying_eff - universal_eff if not np.isnan(universal_eff) else np.nan\n",
    "        print(f\"{event_time:>12} {varying_eff:>12.4f} {universal_eff:>12.4f} {diff:>12.4f}\")\n",
    "\n",
    "print(\"\\nNote: 'Varying' uses consecutive period comparisons (t vs t-1)\")\n",
    "print(\"      'Universal' compares all periods to g-1 (g-anticipation-1 if anticipation > 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Pre-Treatment Effects\n",
    "\n",
    "**What we're testing:**\n",
    "- Pre-treatment ATT(g,t) should be approximately zero if parallel trends holds\n",
    "- Significant non-zero pre-treatment effects suggest potential parallel trends violations\n",
    "\n",
    "**Key insights:**\n",
    "- Visual inspection in the event study plot shows pre-period coefficients\n",
    "- Formal tests: 95% CIs including zero is consistent with parallel trends\n",
    "- **Important caveat**: A \"passing\" test doesn't prove parallel trends—the test may lack power\n",
    "\n",
    "**When concerned about pre-trends:**\n",
    "- Add covariates for precision (Section 11)\n",
    "- Use `control_group=\"not_yet_treated\"` for more data (Section 9)\n",
    "- Apply Honest DiD sensitivity analysis to bound effects under violations (Tutorial 05)\n",
    "- Assess pre-trends test power using Tutorial 07\n",
    "\n",
    "For comprehensive parallel trends testing: **Tutorial 04**\n",
    "For pre-trends power analysis (Roth 2022): **Tutorial 07**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Different Control Group Options\n",
    "\n",
    "The CS estimator supports different control group specifications:\n",
    "- `\"never_treated\"`: Only use units that are never treated\n",
    "- `\"not_yet_treated\"`: Use units that haven't been treated yet at time t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using not-yet-treated as control\n",
    "cs_nyt = CallawaySantAnna(\n",
    "    control_group=\"not_yet_treated\"\n",
    ")\n",
    "\n",
    "results_nyt = cs_nyt.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\"\n",
    ")\n",
    "\n",
    "# Compare using overall_att/overall_se attributes\n",
    "print(\"Comparison of control group specifications:\")\n",
    "print(f\"{'Control Group':<20} {'ATT':>10} {'SE':>10}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Never-treated':<20} {results_cs.overall_att:>10.4f} {results_cs.overall_se:>10.4f}\")\n",
    "print(f\"{'Not-yet-treated':<20} {results_nyt.overall_att:>10.4f} {results_nyt.overall_se:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Handling Anticipation Effects\n",
    "\n",
    "If units start changing behavior before official treatment (anticipation), you can specify the anticipation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow for 1 period of anticipation\n",
    "cs_antic = CallawaySantAnna(\n",
    "    control_group=\"never_treated\",\n",
    "    anticipation=1  # Treatment effects may start 1 period early\n",
    ")\n",
    "\n",
    "results_antic = cs_antic.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\"\n",
    ")\n",
    "\n",
    "print(f\"With anticipation=1: ATT = {results_antic.overall_att:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Adding Covariates\n",
    "\n",
    "You can include covariates to improve precision through outcome regression or propensity score methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add covariates to data\n",
    "df['size'] = np.random.normal(100, 20, len(df))\n",
    "df['age'] = np.random.normal(10, 3, len(df))\n",
    "\n",
    "# Fit with covariates\n",
    "cs_cov = CallawaySantAnna(\n",
    "    control_group=\"never_treated\"\n",
    ")\n",
    "\n",
    "results_cov = cs_cov.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\",\n",
    "    covariates=[\"size\", \"age\"]\n",
    ")\n",
    "\n",
    "print(f\"With covariates: ATT = {results_cov.overall_att:.4f} (SE: {results_cov.overall_se:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparing with MultiPeriodDiD\n",
    "\n",
    "For comparison, here's how you would use `MultiPeriodDiD` which estimates period-specific effects. \n",
    "\n",
    "**Important**: `MultiPeriodDiD` assumes **simultaneous treatment timing** (all treated units get treated at the same time). For staggered adoption, always use `CallawaySantAnna` or `SunAbraham` instead.\n",
    "\n",
    "To demonstrate `MultiPeriodDiD` properly, we'll create a simple dataset where all treated units receive treatment at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dataset with simultaneous treatment timing\n",
    "# This is the appropriate data structure for MultiPeriodDiD\n",
    "from diff_diff import generate_did_data\n",
    "\n",
    "# Generate data with simultaneous treatment at period 4\n",
    "mp_data = generate_did_data(\n",
    "    n_units=100,\n",
    "    n_periods=8,\n",
    "    treatment_period=4,  # All treated units get treatment at period 4\n",
    "    treatment_fraction=0.5,\n",
    "    treatment_effect=2.5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"MultiPeriodDiD dataset: {len(mp_data)} obs\")\n",
    "print(f\"Treatment starts at period 4 for all treated units\")\n",
    "\n",
    "mp_did = MultiPeriodDiD()\n",
    "results_mp = mp_did.fit(\n",
    "    mp_data,\n",
    "    outcome=\"outcome\",\n",
    "    treatment=\"treated\",\n",
    "    time=\"period\",\n",
    "    post_periods=[4, 5, 6, 7]\n",
    ")\n",
    "\n",
    "print(results_mp.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period-specific effects from MultiPeriodDiD\n",
    "print(\"\\nPeriod-specific effects:\")\n",
    "for period, pe in results_mp.period_effects.items():\n",
    "    print(f\"Period {period}: {pe.effect:.4f} (SE: {pe.se:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Sun-Abraham Interaction-Weighted Estimator\n",
    "\n",
    "The Sun-Abraham (2021) estimator provides an alternative approach to staggered DiD. While Callaway-Sant'Anna aggregates 2x2 DiD comparisons, Sun-Abraham uses an **interaction-weighted regression** approach:\n",
    "\n",
    "1. Run a saturated regression with cohort × relative-time indicators\n",
    "2. Weight cohort-specific effects by each cohort's share of treated observations at each relative time\n",
    "\n",
    "**Key differences from CS:**\n",
    "- Regression-based vs. 2x2 DiD aggregation\n",
    "- Different weighting scheme\n",
    "- More efficient under homogeneous effects\n",
    "- Consistent under heterogeneous effects (like CS)\n",
    "\n",
    "**When to use both:** Running both CS and SA provides a useful robustness check. When they agree, results are more credible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sun-Abraham estimation\n",
    "sa = SunAbraham(\n",
    "    control_group=\"never_treated\",  # Use never-treated as controls\n",
    "    anticipation=0                   # No anticipation effects\n",
    ")\n",
    "\n",
    "results_sa = sa.fit(\n",
    "    df,\n",
    "    outcome=\"outcome\",\n",
    "    unit=\"unit\",\n",
    "    time=\"period\",\n",
    "    first_treat=\"first_treat\"  # Column with first treatment period (0 = never treated)\n",
    ")\n",
    "\n",
    "# View summary\n",
    "results_sa.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event study effects by relative time\n",
    "print(\"Sun-Abraham Event Study Effects:\")\n",
    "print(f\"{'Rel. Time':>12} {'Effect':>10} {'SE':>10} {'p-value':>10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for rel_time in sorted(results_sa.event_study_effects.keys()):\n",
    "    eff = results_sa.event_study_effects[rel_time]\n",
    "    sig = \"*\" if eff['p_value'] < 0.05 else \"\"\n",
    "    print(f\"{rel_time:>12} {eff['effect']:>10.4f} {eff['se']:>10.4f} {eff['p_value']:>10.4f} {sig}\")\n",
    "\n",
    "# Cohort weights show how each cohort contributes to event-study estimates\n",
    "print(\"\\n\\nCohort Weights by Relative Time:\")\n",
    "for rel_time in sorted(results_sa.cohort_weights.keys()):\n",
    "    weights = results_sa.cohort_weights[rel_time]\n",
    "    print(f\"e={rel_time}: {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 14. Comparing CS and SA as a Robustness Check\n\nRunning both estimators provides a useful robustness check. When they agree, results are more credible.\n\n### Understanding Pre-Period Differences\n\nYou may notice that **post-treatment effects align closely** between CS and SA, but **pre-treatment effects can differ in magnitude and significance**. This is expected methodological behavior, not a bug.\n\n**Why the difference?**\n\n1. **Callaway-Sant'Anna with `base_period=\"varying\"` (default)**:\n   - Pre-treatment effects use **consecutive period comparisons** (period t vs period t-1)\n   - Each pre-period coefficient represents a one-period change\n   - These smaller incremental changes often yield lower t-statistics\n\n2. **Sun-Abraham**:\n   - Uses a **fixed reference period** (e=-1 when anticipation=0, or e=-1-anticipation otherwise)\n   - All coefficients are deviations from this single reference\n   - Pre-period coefficients show cumulative difference from the reference\n\n**To make CS pre-periods more comparable to SA**, use `base_period=\"universal\"`:\n\n```python\ncs_universal = CallawaySantAnna(base_period=\"universal\")\n```\n\nThis makes CS compare all periods to g-1 (like SA), producing more similar pre-treatment estimates."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare overall ATT from both estimators\nprint(\"Robustness Check: CS vs SA\")\nprint(\"=\" * 60)\nprint(f\"{'Estimator':<30} {'Overall ATT':>12} {'SE':>10}\")\nprint(\"-\" * 60)\nprint(f\"{'Callaway-Sant\\\\'Anna (varying)':<30} {results_cs.overall_att:>12.4f} {results_cs.overall_se:>10.4f}\")\nprint(f\"{'Sun-Abraham':<30} {results_sa.overall_att:>12.4f} {results_sa.overall_se:>10.4f}\")\n\n# Also fit CS with universal base period for comparison\ncs_universal = CallawaySantAnna(control_group=\"never_treated\", base_period=\"universal\")\nresults_cs_univ = cs_universal.fit(\n    df, outcome=\"outcome\", unit=\"unit\",\n    time=\"period\", first_treat=\"first_treat\",\n    aggregate=\"event_study\"\n)\n\n# Compare event study effects\nprint(\"\\n\\nEvent Study Comparison:\")\nprint(\"Note: Pre-periods differ due to base period methodology (see explanation above)\")\nprint(f\"{'Rel. Time':>10} {'CS (vary)':>12} {'CS (univ)':>12} {'SA':>10} {'Note':>20}\")\nprint(\"-\" * 70)\n\nfor rel_time in sorted(results_sa.event_study_effects.keys()):\n    sa_eff = results_sa.event_study_effects[rel_time]['effect']\n    cs_vary = results_cs.event_study_effects.get(rel_time, {}).get('effect', np.nan)\n    cs_univ = results_cs_univ.event_study_effects.get(rel_time, {}).get('effect', np.nan)\n    \n    note = \"pre (differs)\" if rel_time < 0 else \"post (matches)\"\n    print(f\"{rel_time:>10} {cs_vary:>12.4f} {cs_univ:>12.4f} {sa_eff:>10.4f} {note:>20}\")\n\nprint(\"\\nPost-treatment effects should be similar across all methods\")\nprint(\"Pre-treatment differences are expected due to base period methodology\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nKey takeaways:\n\n1. **TWFE can be biased** with staggered adoption and heterogeneous effects\n2. **Goodman-Bacon decomposition** reveals *why* TWFE fails by showing:\n   - The implicit 2x2 comparisons and their weights\n   - How much weight falls on \"forbidden comparisons\" (already-treated as controls)\n3. **Callaway-Sant'Anna** properly handles staggered adoption by:\n   - Computing group-time specific effects ATT(g,t)\n   - Only using valid comparison groups\n   - Properly aggregating effects\n4. **Sun-Abraham** provides an alternative approach using:\n   - Interaction-weighted regression with cohort x relative-time indicators\n   - Different weighting scheme than CS\n   - More efficient under homogeneous effects\n5. **Run both CS and SA** as a robustness check—when they agree, results are more credible\n6. **Aggregation options**:\n   - `\"simple\"`: Overall ATT\n   - `\"group\"`: ATT by cohort\n   - `\"event\"`: ATT by event time (for event-study plots)\n7. **Bootstrap inference** provides valid standard errors and confidence intervals:\n   - Use `n_bootstrap` parameter to enable multiplier bootstrap\n   - Choose weight type: `'rademacher'`, `'mammen'`, or `'webb'`\n   - Bootstrap results include SEs, CIs, and p-values for all aggregations\n8. **Pre-treatment effects** provide parallel trends diagnostics:\n   - Use `base_period=\"varying\"` for consecutive period comparisons\n   - Pre-treatment ATT(g,t) should be near zero\n   - 95% CIs including zero is consistent with parallel trends\n   - See Tutorial 07 for pre-trends power analysis (Roth 2022)\n9. **Control group choices** affect efficiency and assumptions:\n   - `\"never_treated\"`: Stronger parallel trends assumption\n   - `\"not_yet_treated\"`: Weaker assumption, uses more data\n10. **CS vs SA pre-period differences are expected**:\n    - Post-treatment effects should be similar (robustness check)\n    - Pre-treatment effects differ due to base period methodology\n    - CS (varying): consecutive comparisons → one-period changes\n    - SA: fixed reference (e=-1-anticipation) → cumulative deviations\n    - Use `base_period=\"universal\"` in CS for comparable pre-periods\n\nFor more details, see:\n- Callaway, B., & Sant'Anna, P. H. (2021). Difference-in-differences with multiple time periods. *Journal of Econometrics*.\n- Sun, L., & Abraham, S. (2021). Estimating dynamic treatment effects in event studies with heterogeneous treatment effects. *Journal of Econometrics*.\n- Goodman-Bacon, A. (2021). Difference-in-differences with variation in treatment timing. *Journal of Econometrics*."
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}