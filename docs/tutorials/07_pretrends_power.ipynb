{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Pre-Trends Power Analysis (Roth 2022)\n",
    "\n",
    "A passing pre-trends test doesn't mean parallel trends holds—it may just mean the test has **low power** to detect violations. **Pre-Trends Power Analysis** (Roth 2022) answers a critical question:\n",
    "\n",
    "> \"What violations could my pre-trends test have detected?\"\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "1. Motivation: Why pre-trends tests can be misleading\n",
    "2. Basic usage with `PreTrendsPower`\n",
    "3. Computing the Minimum Detectable Violation (MDV)\n",
    "4. Power curves across violation magnitudes\n",
    "5. Different violation types (linear, constant, last period, custom)\n",
    "6. Integration with Honest DiD\n",
    "7. Visualization and reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from diff_diff import (\n",
    "    MultiPeriodDiD,\n",
    "    PreTrendsPower,\n",
    "    compute_pretrends_power,\n",
    "    compute_mdv,\n",
    "    plot_pretrends_power,\n",
    ")\n",
    "\n",
    "# For plots\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    HAS_MATPLOTLIB = False\n",
    "    print(\"matplotlib not installed - visualization examples will be skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Motivation: The Problem with Pre-Trends Tests\n",
    "\n",
    "Standard practice in DiD analysis is to test for parallel trends by checking if pre-treatment coefficients are jointly zero. However, this approach has a fundamental problem:\n",
    "\n",
    "**A non-significant pre-trends test could mean:**\n",
    "1. Parallel trends actually holds ✓\n",
    "2. There's a violation, but the test lacks power to detect it ✗\n",
    "\n",
    "**Why does this matter?**\n",
    "\n",
    "If your pre-trends test has low power, it provides little reassurance about the validity of your DiD. Even a \"passing\" test (p > 0.05) might miss economically meaningful violations.\n",
    "\n",
    "**Roth (2022) introduces two key concepts:**\n",
    "\n",
    "1. **Power of the pre-trends test**: The probability of rejecting the null (parallel trends) when there *is* a violation of a given magnitude\n",
    "\n",
    "2. **Minimum Detectable Violation (MDV)**: The smallest violation your pre-trends test can detect with a target level of power (e.g., 80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Generate Example Data\n",
    "\n",
    "We'll create panel data suitable for event study analysis with multiple pre-treatment periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_event_study_data(n_units=300, n_periods=10, true_att=5.0, seed=42):\n",
    "    \"\"\"\n",
    "    Generate panel data for event study analysis.\n",
    "    \n",
    "    - 5 pre-treatment periods (0-4)\n",
    "    - 5 post-treatment periods (5-9)\n",
    "    - Half of units are treated starting at period 5\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    treatment_time = n_periods // 2\n",
    "    \n",
    "    data = []\n",
    "    for unit in range(n_units):\n",
    "        is_treated = unit < n_units // 2\n",
    "        unit_effect = np.random.normal(0, 2)\n",
    "        \n",
    "        for period in range(n_periods):\n",
    "            # Common time trend\n",
    "            time_effect = period * 0.5\n",
    "            \n",
    "            y = 10.0 + unit_effect + time_effect\n",
    "            \n",
    "            # Treatment effect (only post-treatment)\n",
    "            post = period >= treatment_time\n",
    "            if is_treated and post:\n",
    "                y += true_att\n",
    "            \n",
    "            y += np.random.normal(0, 2)\n",
    "            \n",
    "            data.append({\n",
    "                'unit': unit,\n",
    "                'period': period,\n",
    "                'treated': int(is_treated),\n",
    "                'post': int(post),\n",
    "                'outcome': y\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate data\n",
    "df = generate_event_study_data()\n",
    "print(f\"Generated {len(df)} observations\")\n",
    "print(f\"Units: {df['unit'].nunique()} ({df[df['treated']==1]['unit'].nunique()} treated)\")\n",
    "print(f\"Periods: {df['period'].nunique()} (5 pre, 5 post)\")\n",
    "print(f\"True ATT: 5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 3. Fit Event Study\n",
    "\n",
    "First, we estimate a standard event study to get the pre-period coefficients and their variance-covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit event study\n",
    "mp_did = MultiPeriodDiD()\n",
    "event_results = mp_did.fit(\n",
    "    df,\n",
    "    outcome='outcome',\n",
    "    treatment='treated',\n",
    "    time='period',\n",
    "    post_periods=[5, 6, 7, 8, 9]  # Periods 5-9 are post-treatment\n",
    ")\n",
    "\n",
    "print(event_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the event study\n",
    "if HAS_MATPLOTLIB:\n",
    "    from diff_diff import plot_event_study\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plot_event_study(\n",
    "        event_results,\n",
    "        ax=ax,\n",
    "        title='Event Study: Pre-Trends Look Good',\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "The pre-period coefficients (periods 0-3, with period 4 as reference) appear close to zero. But how confident should we be that parallel trends holds? Let's assess the **power** of this pre-trends test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Basic Pre-Trends Power Analysis\n",
    "\n",
    "The `PreTrendsPower` class computes the power of the pre-trends test to detect violations of different magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PreTrendsPower object\n",
    "pt = PreTrendsPower(\n",
    "    alpha=0.05,      # Significance level for pre-trends test\n",
    "    power=0.80,      # Target power for MDV calculation\n",
    "    violation_type='linear'  # Type of violation to consider\n",
    ")\n",
    "\n",
    "# Fit to the event study results\n",
    "pt_results = pt.fit(event_results)\n",
    "\n",
    "print(pt_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### Interpreting the Results\n",
    "\n",
    "**Key metrics:**\n",
    "\n",
    "1. **MDV (Minimum Detectable Violation)**: The smallest violation magnitude your pre-trends test can detect with 80% power\n",
    "   - Smaller MDV = more informative test\n",
    "   - If MDV is large, even big violations could go undetected\n",
    "\n",
    "2. **Power at specific violations**: How likely is the test to reject when there's a violation?\n",
    "   - Low power = uninformative \"passing\" test\n",
    "   - High power = reassuring \"passing\" test\n",
    "\n",
    "3. **Test informativeness**: Is the MDV small enough to be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access key results\n",
    "print(f\"Minimum Detectable Violation (MDV): {pt_results.mdv:.4f}\")\n",
    "print(f\"Target power: {pt_results.target_power:.0%}\")\n",
    "print(f\"Test informativeness: {'Informative' if pt_results.is_informative else 'Uninformative'}\")\n",
    "print(\"\")\n",
    "print(\"Interpretation:\")\n",
    "print(f\"  With 80% power, your pre-trends test can detect violations\")\n",
    "print(f\"  of magnitude {pt_results.mdv:.3f} or larger.\")\n",
    "print(f\"\")\n",
    "print(f\"  Violations smaller than {pt_results.mdv:.3f} would likely go undetected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Power at Specific Violation Magnitudes\n",
    "\n",
    "You can compute the power to detect a specific violation magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute power for specific violation magnitudes\n",
    "violations_to_check = [0.5, 1.0, 2.0, 3.0, 5.0]\n",
    "\n",
    "print(f\"{'Violation':>12} {'Power':>10} {'Detectable?':>15}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for v in violations_to_check:\n",
    "    power = pt_results.power_at(v)\n",
    "    detectable = \"Yes\" if power >= 0.80 else \"No\"\n",
    "    print(f\"{v:>12.1f} {power:>10.1%} {detectable:>15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Power Curves\n",
    "\n",
    "A **power curve** shows how the power to detect violations changes with violation magnitude. This is the most useful visualization for understanding your test's informativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# Generate power curve\ncurve = pt.power_curve(\n    event_results,\n    n_points=50\n)\n\n# Preview the data\nprint(\"Power curve data (first 10 points):\")\nprint(curve.to_dataframe().head(10))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the power curve\n",
    "if HAS_MATPLOTLIB:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plot_pretrends_power(\n",
    "        curve,\n",
    "        ax=ax,\n",
    "        show_mdv=True,\n",
    "        target_power=0.80,\n",
    "        title='Pre-Trends Test Power Curve',\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "### Reading the Power Curve\n",
    "\n",
    "- **X-axis**: Violation magnitude (larger = worse violation of parallel trends)\n",
    "- **Y-axis**: Power (probability of rejecting when violation exists)\n",
    "- **Horizontal line at 0.80**: Conventional target power\n",
    "- **Vertical line at MDV**: Minimum detectable violation\n",
    "\n",
    "**Key insight**: The curve shows the range of violations your test could miss. If your ATT estimate could be biased by a violation smaller than the MDV, your results may be unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 7. Different Violation Types\n",
    "\n",
    "Pre-trends violations can take different forms. The `violation_type` parameter specifies the pattern:\n",
    "\n",
    "1. **Linear** (default): Violation grows linearly over time\n",
    "   - E.g., treated group diverges steadily from control\n",
    "   \n",
    "2. **Constant**: Same violation in all pre-periods\n",
    "   - E.g., level shift between groups\n",
    "   \n",
    "3. **Last period**: Violation only in the period just before treatment\n",
    "   - E.g., anticipation effects\n",
    "   \n",
    "4. **Custom**: User-specified violation pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare violation types\n",
    "violation_types = ['linear', 'constant', 'last_period']\n",
    "\n",
    "print(f\"{'Violation Type':>15} {'MDV':>10} {'Power at 2.0':>15}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for vtype in violation_types:\n",
    "    pt_v = PreTrendsPower(violation_type=vtype)\n",
    "    results_v = pt_v.fit(event_results)\n",
    "    power_at_2 = results_v.power_at(2.0)\n",
    "    print(f\"{vtype:>15} {results_v.mdv:>10.3f} {power_at_2:>15.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom violation weights\n",
    "# Example: Violation concentrated in periods 2 and 3 (approaching treatment)\n",
    "n_pre = len([e for e in event_results.period_effects if e.relative_time < 0])\n",
    "custom_weights = np.zeros(n_pre)\n",
    "custom_weights[-2:] = 1.0  # Weight on last two pre-periods\n",
    "\n",
    "pt_custom = PreTrendsPower(\n",
    "    violation_type='custom',\n",
    "    violation_weights=custom_weights\n",
    ")\n",
    "results_custom = pt_custom.fit(event_results)\n",
    "\n",
    "print(f\"Custom violation (last 2 periods): MDV = {results_custom.mdv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Visualizing Different Violation Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "if HAS_MATPLOTLIB:\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n    \n    for ax, vtype in zip(axes, ['linear', 'constant', 'last_period']):\n        pt_v = PreTrendsPower(violation_type=vtype)\n        curve_v = pt_v.power_curve(event_results, n_points=50)\n        \n        plot_pretrends_power(\n            curve_v,\n            ax=ax,\n            show_mdv=True,\n            target_power=0.80,\n            title=f'Violation Type: {vtype.replace(\"_\", \" \").title()}',\n            show=False\n        )\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 8. Integration with Honest DiD\n",
    "\n",
    "Pre-trends power analysis connects naturally with **Honest DiD** (Rambachan & Roth 2023). The workflow:\n",
    "\n",
    "1. Compute MDV from pre-trends power analysis\n",
    "2. Use MDV to calibrate the violation bound (M) in Honest DiD\n",
    "3. Compute robust confidence intervals under this calibrated bound\n",
    "\n",
    "This answers: \"If violations could be as large as what my pre-trends test could have missed, would my conclusions still hold?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_diff import HonestDiD\n",
    "\n",
    "# First, compute MDV\n",
    "pt = PreTrendsPower(violation_type='linear')\n",
    "pt_results = pt.fit(event_results)\n",
    "\n",
    "print(f\"MDV from pre-trends power analysis: {pt_results.mdv:.3f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Use MDV to calibrate Honest DiD\n",
    "# The MDV tells us what violations we couldn't have detected\n",
    "# So we should check robustness to violations up to the MDV\n",
    "honest = HonestDiD(method='smoothness', M=pt_results.mdv)\n",
    "honest_results = honest.fit(event_results)\n",
    "\n",
    "print(\"Honest DiD results (M = MDV):\")\n",
    "print(honest_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in sensitivity integration\n",
    "sensitivity_results = pt.sensitivity_to_honest_did(\n",
    "    event_results,\n",
    "    honest_method='smoothness'\n",
    ")\n",
    "\n",
    "print(\"Joint sensitivity analysis:\")\n",
    "print(f\"  MDV: {sensitivity_results['mdv']:.3f}\")\n",
    "print(f\"  Original estimate: {sensitivity_results['original_estimate']:.3f}\")\n",
    "print(f\"  Robust CI at M=MDV: [{sensitivity_results['ci_lb']:.3f}, {sensitivity_results['ci_ub']:.3f}]\")\n",
    "print(f\"  Significant at M=MDV: {sensitivity_results['significant_at_mdv']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## 9. Convenience Functions\n",
    "\n",
    "For quick calculations, use the convenience functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick MDV calculation\n",
    "mdv = compute_mdv(event_results, power=0.80, violation_type='linear')\n",
    "print(f\"MDV: {mdv:.3f}\")\n",
    "\n",
    "# Quick power calculation at a specific violation\n",
    "power = compute_pretrends_power(event_results, violation_magnitude=2.0)\n",
    "print(f\"Power at violation=2.0: {power:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 10. Working with Real Event Studies\n",
    "\n",
    "In practice, you'll apply pre-trends power analysis to your actual event study estimates. Here's the typical workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typical workflow for pre-trends power analysis\n",
    "\n",
    "# Step 1: Estimate event study\n",
    "mp_did = MultiPeriodDiD()\n",
    "results = mp_did.fit(\n",
    "    df, \n",
    "    outcome='outcome',\n",
    "    treatment='treated', \n",
    "    time='period',\n",
    "    post_periods=[5, 6, 7, 8, 9]\n",
    ")\n",
    "\n",
    "# Step 2: Check standard parallel trends test\n",
    "print(\"Step 2: Standard Pre-Trends Test\")\n",
    "print(f\"Pre-trends test p-value: {results.pretrend_test_pvalue:.4f}\")\n",
    "print(f\"Conclusion: {'Fail to reject parallel trends' if results.pretrend_test_pvalue > 0.05 else 'Reject parallel trends'}\")\n",
    "print(\"\")\n",
    "\n",
    "# Step 3: Assess power of the pre-trends test  \n",
    "print(\"Step 3: Pre-Trends Power Analysis\")\n",
    "pt = PreTrendsPower(alpha=0.05, power=0.80, violation_type='linear')\n",
    "pt_results = pt.fit(results)\n",
    "print(f\"MDV (80% power): {pt_results.mdv:.3f}\")\n",
    "print(\"\")\n",
    "\n",
    "# Step 4: Interpret\n",
    "print(\"Step 4: Interpretation\")\n",
    "print(f\"Your pre-trends test could only detect violations >= {pt_results.mdv:.3f}\")\n",
    "print(f\"Violations smaller than this would likely go undetected.\")\n",
    "print(\"\")\n",
    "\n",
    "# Step 5: Connect to Honest DiD for robust inference\n",
    "print(\"Step 5: Robust Inference with Honest DiD\")\n",
    "honest = HonestDiD(method='smoothness', M=pt_results.mdv)\n",
    "honest_results = honest.fit(results)\n",
    "print(f\"Robust 95% CI (M=MDV): [{honest_results.ci_lb:.3f}, {honest_results.ci_ub:.3f}]\")\n",
    "print(f\"Conclusion: {'Effect is robust' if honest_results.is_significant else 'Effect may not be robust'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 11. Exporting Results\n",
    "\n",
    "Results can be exported to DataFrames for further analysis or reporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export single result\n",
    "print(\"Single result as DataFrame:\")\n",
    "print(pt_results.to_dataframe())\n",
    "print(\"\")\n",
    "\n",
    "# Export power curve\n",
    "print(\"Power curve as DataFrame (first 10 rows):\")\n",
    "curve = pt.power_curve(event_results)\n",
    "print(curve.to_dataframe().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to dict for JSON serialization\n",
    "result_dict = pt_results.to_dict()\n",
    "print(\"Result as dictionary:\")\n",
    "for key, value in result_dict.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Pre-trends tests can be misleading**: A \"passing\" test (p > 0.05) doesn't mean parallel trends holds—it may mean the test has low power.\n",
    "\n",
    "2. **MDV quantifies test informativeness**: The Minimum Detectable Violation tells you the smallest violation your test could detect with 80% power.\n",
    "\n",
    "3. **Power curves visualize sensitivity**: See how detection power changes with violation magnitude.\n",
    "\n",
    "4. **Different violation types matter**: Linear, constant, and last-period violations have different detectability.\n",
    "\n",
    "5. **Integration with Honest DiD**: Use MDV to calibrate sensitivity analysis bounds.\n",
    "\n",
    "**Best Practices:**\n",
    "\n",
    "- Always report pre-trends power analysis alongside standard pre-trends tests\n",
    "- Include power curves in supplementary materials\n",
    "- Use MDV to calibrate Honest DiD sensitivity analysis\n",
    "- Consider multiple violation types\n",
    "- Discuss what violation magnitudes would be economically meaningful in your setting\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "Roth, J. (2022). Pretest with Caution: Event-Study Estimates after Testing for Parallel Trends. *American Economic Review: Insights*, 4(3), 305-322. https://doi.org/10.1257/aeri.20210236"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-35",
   "metadata": {},
   "source": [
    "## Related Tutorials\n",
    "\n",
    "- `04_parallel_trends.ipynb` - Testing and visualizing parallel trends\n",
    "- `05_honest_did.ipynb` - Sensitivity analysis for parallel trends violations\n",
    "- `06_power_analysis.ipynb` - Power analysis for study design (sample size, MDE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}